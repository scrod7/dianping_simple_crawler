[config]
# 是否使用cookie池，使用为True，反之为False，如果为True，则Cookie（下面这个参数）不被读取，在cookies.txt中配置所有cookie
use_cookie_pool = False
;# cookie 如果为不需要cookie的任务则可不填，cookie相关的具体使用规则可以查看readme中碎碎念的有关cookie
Cookie: # uuid，获取方法详见文档，使用加密接口时使用
uuid :
# tcv，获取方法详见文档，使用加密接口时使用
tcv =
# 默认user-agent,如果为None则为随机（仅可在不需要cookie的任务中使用,登录状态不建议随机user-agent）
user-agent = Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/128.0.0.0 Safari/537.36
# 保存方式  暂时支持csv和mongo
save_mode = csv
# mongodb 链接 （mongodb://servername:port，如果本地默认端口（27017）可不填）
mongo_path = 
# 累计请求多少次休息多少秒，从小到大排列。例：1,2;5,10 代表每请求1次休息2秒，每5次休息10秒。
requests_times = 1,2;3,5;10,50

[detail]
# 搜索关键字
keyword = 炸鸡
# 位置代号，如上海为1  北京为2 广州为4，暂时不支持地名自动转换id
location_id = 1
# 爬取多个城市
city_ids = 1
cities = 银川,乌鲁木齐,香港,澳门
channel_id = 0
# 搜索页链接，用于非'http://www.dianping.com/search/keyword/(location_id)/(channel_id)_(key_word)/p(page_nub)的情况
# 如果不填，则默认填充上述url，填充后上述参数默认无效
# 注，填充的时候需要填充到p，例如：http://www.dianping.com/dalian/ch10/g110p2 填充http://www.dianping.com/dalian/ch10/g110p
search_url =
# 是否只需要搜索页的首条内容
need_first = False
# 需要搜索的页数
need_pages = 14
shop_phone=False
[proxy]
use_proxy = False
# ip 重复次数，由于非隧道模式时，一个ip常常有1分钟左右的有效时间，单次使用有点浪费，重复使用次数
repeat_nub = 5
# 代理模式为http提取
http_extract = True
# 代理模式为秘钥访问
key_extract = False
# http链接（秘钥模式不必填）
http_link =
# 代理服务器
proxy_host =
# 代理服务器端口
proxy_port =
# 秘钥id（http模式不必填）
key_id =
# 秘钥key（http模式不必填）
key_key =

